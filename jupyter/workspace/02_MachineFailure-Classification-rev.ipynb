{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bac0a3",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "For our example, we’ll use the AI4I 2020 Predictive Maintenance Dataset\n",
    "((2020) UCI Machine Learning Repository\n",
    "(https://doi.org/10.24432/C5HS5C). This synthetic dataset is modeled after\n",
    "an existing milling machine and consists of 10,000 data points stored as rows\n",
    "with 14 features in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d5f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0c3f2",
   "metadata": {},
   "source": [
    "### import the required libraries and create spark session\n",
    "The following lines of code imports all the required packages and libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db865ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 18:17:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/13 18:17:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/11/13 18:17:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "#import the library and create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"ClassificationExample\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4d960",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data and create dataframe\n",
    "The following code snippet loads the dataset and prints out the DataFrame\n",
    "and its schema and display the first 3 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d3b0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----+-----------------+---------------------+--------------------+---------+-------------+---------------+-----------------+------------------------+-------------+------------------+---------------+\n",
      "|UDI|Product ID|type|air_temperature_k|process_temperature_k|rotational_speed_rpm|torque_nm|tool_wear_min|machine_failure|tool_wear_failure|heat_dissipation_failure|power_failure|overstrain_failure|random_failures|\n",
      "+---+----------+----+-----------------+---------------------+--------------------+---------+-------------+---------------+-----------------+------------------------+-------------+------------------+---------------+\n",
      "|1  |M14860    |M   |298.1            |308.6                |1551                |42.8     |0            |0              |0                |0                       |0            |0                 |0              |\n",
      "|2  |L47181    |L   |298.2            |308.7                |1408                |46.3     |3            |0              |0                |0                       |0            |0                 |0              |\n",
      "|3  |L47182    |L   |298.1            |308.5                |1498                |49.4     |5            |0              |0                |0                       |0            |0                 |0              |\n",
      "+---+----------+----+-----------------+---------------------+--------------------+---------+-------------+---------------+-----------------+------------------------+-------------+------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.csv(\"machine_failure_data.csv\", header=True, inferSchema=True)\n",
    "train_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b2dca",
   "metadata": {},
   "source": [
    "### Preprocessing the data: Convert all integer columns to float, remove null values and print the schema\n",
    "\n",
    "The following code snippet converts integer columns into floats, removes the\n",
    "null values, and prints the data schema:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89a9a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UDI: float (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- air_temperature_k: double (nullable = true)\n",
      " |-- process_temperature_k: double (nullable = true)\n",
      " |-- rotational_speed_rpm: float (nullable = true)\n",
      " |-- torque_nm: double (nullable = true)\n",
      " |-- tool_wear_min: float (nullable = true)\n",
      " |-- machine_failure: float (nullable = true)\n",
      " |-- tool_wear_failure: float (nullable = true)\n",
      " |-- heat_dissipation_failure: float (nullable = true)\n",
      " |-- power_failure: float (nullable = true)\n",
      " |-- overstrain_failure: float (nullable = true)\n",
      " |-- random_failures: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert all integer columns in train_df to float\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "for col in train_df.columns:\n",
    "    if train_df.schema[col].dataType == IntegerType():\n",
    "        train_df = train_df.withColumn(col, train_df[col].cast(FloatType()))\n",
    "# remove null values\n",
    "train_df = train_df.dropna()\n",
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd5b48",
   "metadata": {},
   "source": [
    "### Prepare the data by removing the id columns and failure columns retaining only the machine failure column\n",
    "\n",
    "\n",
    "The following code snippet performs feature engineering by removing the\n",
    "unwanted columns, replacing the missing values, and converting the\n",
    "categorical column into a numerical one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ac050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+---------------------+--------------------+---------+-------------+---------------+\n",
      "|type|air_temperature_k|process_temperature_k|rotational_speed_rpm|torque_nm|tool_wear_min|machine_failure|\n",
      "+----+-----------------+---------------------+--------------------+---------+-------------+---------------+\n",
      "|M   |298.1            |308.6                |1551.0              |42.8     |0.0          |0.0            |\n",
      "|L   |298.2            |308.7                |1408.0              |46.3     |3.0          |0.0            |\n",
      "|L   |298.1            |308.5                |1498.0              |49.4     |5.0          |0.0            |\n",
      "+----+-----------------+---------------------+--------------------+---------+-------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drope the id columns such as UDI, Product ID,heat_dissipation_failure,power_failure,overstrain_failure,random_failures,tool_wear_failure\n",
    "train_df = train_df.drop(\"UDI\",\"Product ID\",\"heat_dissipation_failure\",\"power_failure\",\"overstrain_failure\",\"random_failures\",\"tool_wear_failure\")\n",
    "train_df.show(3,truncate=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b63092",
   "metadata": {},
   "source": [
    "# Feature Engineering: Fill missing values, convert the type column to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213b3cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+---------------------+--------------------+---------+-------------+---------------+----------+\n",
      "|type|air_temperature_k|process_temperature_k|rotational_speed_rpm|torque_nm|tool_wear_min|machine_failure|type_index|\n",
      "+----+-----------------+---------------------+--------------------+---------+-------------+---------------+----------+\n",
      "|   M|            298.1|                308.6|              1551.0|     42.8|          0.0|            0.0|       1.0|\n",
      "|   L|            298.2|                308.7|              1408.0|     46.3|          3.0|            0.0|       0.0|\n",
      "|   L|            298.1|                308.5|              1498.0|     49.4|          5.0|            0.0|       0.0|\n",
      "+----+-----------------+---------------------+--------------------+---------+-------------+---------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#replace  the missing values with 0\n",
    "train_df = train_df.fillna(0)\n",
    "# convert the type column to index\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"type\", outputCol=\"type_index\")\n",
    "train_df = indexer.fit(train_df).transform(train_df)\n",
    "train_df.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66f468",
   "metadata": {},
   "source": [
    "### Feature Engineering using vector assembler\n",
    "The following code snippet generates the feature through the vector function\n",
    "and normalizes the column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cfbb1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|            features|machine_failure|\n",
      "+--------------------+---------------+\n",
      "|[298.1,308.6,1551...|            0.0|\n",
      "|[298.2,308.7,1408...|            0.0|\n",
      "|[298.1,308.5,1498...|            0.0|\n",
      "+--------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply vector assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"air_temperature_k\", \"process_temperature_k\", \"rotational_speed_rpm\", \"torque_nm\", \"tool_wear_min\",\"type_index\"], outputCol=\"features\")\n",
    "train_df = assembler.transform(train_df)\n",
    "train_df.select(\"features\", \"machine_failure\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5cf1f",
   "metadata": {},
   "source": [
    "### Applying standard scaler and show the scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88363bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|      scaledFeatures|machine_failure|\n",
      "+--------------------+---------------+\n",
      "|[149.030724148837...|            0.0|\n",
      "|[149.080717682600...|            0.0|\n",
      "|[149.030724148837...|            0.0|\n",
      "+--------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply standard scaler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(train_df)\n",
    "train_df = scalerModel.transform(train_df)\n",
    "# show the scaled features\n",
    "train_df.select(\"scaledFeatures\", \"machine_failure\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f07ccc",
   "metadata": {},
   "source": [
    "### Split the data into train and test and select the features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e535e1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "train_df, test_df = train_df.randomSplit([0.7, 0.3])\n",
    "# select the features and label\n",
    "train_df = train_df.select(\"scaledFeatures\", \"machine_failure\")\n",
    "test_df = test_df.select(\"scaledFeatures\", \"machine_failure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13c174",
   "metadata": {},
   "source": [
    "### Train the model using Logistic Regression\n",
    "\n",
    "The following code snippet splits the dataset into train and test tests. It then\n",
    "trains the model using LogisticRegression and evaluates the model’s\n",
    "performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4697d63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/13 18:20:53 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:53 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:53 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:54 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:54 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:55 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:55 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:55 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:55 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:56 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:56 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:56 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:57 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:57 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:57 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:57 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:58 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:58 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:58 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:58 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:59 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:59 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:20:59 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:00 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:00 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:00 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:00 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:01 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:01 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:01 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:01 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:02 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:02 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:02 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:02 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:02 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:03 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:03 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:03 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:03 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:03 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:04 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:04 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:04 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:04 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:05 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:05 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:05 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:05 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:05 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:06 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:06 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:06 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:06 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:07 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:07 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:07 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:07 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:08 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:08 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:08 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:08 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:09 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:09 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:09 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:09 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:10 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:10 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:10 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:10 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:10 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:11 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:11 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:11 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:11 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:11 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:12 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:12 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:12 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:12 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:12 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:13 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:13 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:13 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:13 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:13 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:14 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:14 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:14 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:14 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:14 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:15 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:15 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:15 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:15 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:15 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:16 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:16 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n",
      "25/11/13 18:21:16 ERROR LBFGS: Failure! Resetting history: breeze.optimize.FirstOrderException: Line search failed\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"machine_failure\")\n",
    "lrModel = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95157c9",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c90627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313237612372716"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"machine_failure\")\n",
    "evaluator.evaluate(lrModel.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5454d",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this chapter, we explored the fundamental concepts and techniques of\n",
    "classification within the supervised learning. Classification stands\n",
    "as a pivotal task in machine learning, allowing data to be classified into\n",
    "predefined classes. \n",
    "\n",
    "At this point, you should possess a robust understanding of classification and\n",
    "be well-prepared to apply these techniques to address complex problems,\n",
    "marking a significant milestone in your journey through the fascinating\n",
    "world of machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
